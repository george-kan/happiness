---
title: "Explaining Happiness"
output: 
  html_document:
    toc: true
    code_folding: "hide"
    theme: readable    
---


```{r libraries, include=F}
rm(list = ls())
devtools::install_github("hadley/emo")
library(emo)
library(data.table)
library(tidyverse)
library(scales)
library(glue)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(rgeos)
library(showtext)
library(ggsci)
library(ggtext)
library(mice)
library(plotly)
font_add_google("Poppins", "Poppins")
font_add_google("Roboto Mono", "Roboto Mono")
showtext_auto()


#theme_set(theme_minimal())
theme_set(theme_light(base_size = 20, base_family = "Poppins") + 
            theme(plot.title = element_text(size = 20),
                  axis.text = element_text(size=16),
                  legend.text = element_text(size = 14)))
```


Welcome to another notebook! `r emo::ji("stars")`  
The aim of this analysis is to see how we can use external datasources to interpret a variable of interest.  NEED TO CHANGE THAT
In particular, we will combine 2 Kaggle datasets and use the results to decompose the happiness index. 

# 1. Time to meet our datasets

## 1.1 World happiness report

The first dataset we are going to use is the [World happiness report 2021](https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021). The only information that we are going to use from this dataset is the Happiness index and the country. We will try to explain the index using additional datasets from Kaggle.

```{r loading_happiness, echo=F, results='asis'}
hap_dt = fread("C:/Users/George/Desktop/Projects/Happiness/Happiness/world-happiness-report-2021.csv", select=c("Country name", "Ladder score"))
setnames(hap_dt, c("Country name", "Ladder score"), c("Country", "Happiness"))

knitr::kable(head(hap_dt))
```

First dataset loaded! `r emo::ji("check")`

## 1.2 World data

The second dataset we are going to use is the [World data by country](https://www.kaggle.com/daniboy370/world-data-by-country-2020) dataset, which contains data by country for the following indicators:

* GDP per capita
* Population growth
* Life expectancy	 
* Median age	
* Meat consumption	
* Sex-ratio	
* Suicide rate	
* Urbanization	
* Fertility rate	

Each indicator has a corresponding file so we will put all of them together into a single dataframe.


```{r loading_world_data, echo = F, results='asis'}
# Putting together world data
world_data_directory = "C:/Users/George/Desktop/Projects/Happiness/World data/"

for (file in list.files(world_data_directory)){
    
    # Reading data and removing duplicates
    new_dt = fread(glue("{world_data_directory}{file}"))
    new_dt[, country_counter := 1:.N, by = `ISO-code`]
    new_dt = new_dt[country_counter == 1][, country_counter := NULL]
        
    if (!exists("world_dt")) {
        world_dt = new_dt
    } else {
        world_dt = merge(world_dt, new_dt, on = "ISO-code", all=T)        
    }    
}

knitr::kable(head(world_dt))
```

Looks good! `r emo::ji("check")`

## 1.3 World health statistics

The third dataset at our disposal is the [World health statistics](https://www.kaggle.com/utkarshxy/who-worldhealth-statistics-2020-complete), which contains again country indicator information in individual csv files. The structure of the files is not uniform here, so reading the files and putting them together is more complex. Feel free to have a look at the helper functions used!

In terms of indicators, I chose to include the following:

* HEALTHY_LIFE_EXP <span> &rarr;</span> Healthy life expectancy (HALE) at birth measured in years.
* CCDR3070 <span> &rarr;</span> Probability of dying between the age of 30 and 70 from any of: cardiovascular disease, cancer, diabetes, or chronic respiratory disease.  
* CHILD_MORT <span> &rarr;</span> Probability of children dying below the age of 5 per 1000 live births.  
* ALCOHOL_AB <span> &rarr;</span> Total (recorded + unrecorded) alcohol per capita (15+) consumption.  
* POL_DRATE <span> &rarr;</span> Ambient and household air pollution attributable death rate per 100,00 population.  
* WASH_MORT <span> &rarr;</span> Mortality rate attributed to exposure to unsafe WASH services per 100,000 population.  
* POISON_MORT <span> &rarr;</span> Mortality rate attributed to unintentional poisoning per 100,000 population.  
* MATERNAL_MORT <span> &rarr;</span> Maternal mortality ratio per 100,000 births.  
* TUBERC <span> &rarr;</span> Incidence of TB per 100,000 population per year.  
* NTD <span> &rarr;</span> Reported number of people requiring interventions against NTDs.
* ROADTRAFFIC_MORT <span> &rarr;</span> Estimated road traffic death rate per 100,000 population.  
* UNIV_HEALTHCARE <span> &rarr;</span> UHC index of service coverage (SCI).     
* MEDICS <span> &rarr;</span> Medical doctors per 10,000 population.  
* DENTISTS <span> &rarr;</span> Dentists available per 10,000 population.  
* DRINKING_WATER <span> &rarr;</span> Population using at least basic drinking water services (%), sanitation and hygiene.  
* CLEAN_FUEL_TECH <span> &rarr;</span> Proportion of population with primary reliance on clean fuels and technologies (%).  


```{r functions_health_data, include=F} 

read_data <- function (file_name) {
    fread(glue("{health_data_directory}{file_name}"))
}

get_latest_period <- function(dt) {
    dt[, max_country_period := max(Period), by = Location][Period == max_country_period][, max_country_period := NULL]
}

concatenate_health_files <- function(file_cat_l, function_l) {
    for (file_ind in 1:length(file_cat_l)){
        file_cat = file_cat_l[[file_ind]]
        file_function = function_l[[file_ind]]

        for (file in 1:length(file_cat)){
            new_dt = file_function(file_cat[file], names(file_cat[file]))
            if (!exists("res_dt")) {
                res_dt = new_dt
            } else {
                res_dt = merge(res_dt, new_dt, by = "Location", all=T)
            }
        }
    }
    #print(nrow(res_dt))
    return(res_dt)
}

filter_conv <- function (file_name, var_name) {
    dt = read_data(file_name)
    dt = get_latest_period(dt)
    res = dt[Dim1 == "Both sexes", .(Location, TEMP = as.numeric(gsub("^(.*)\\s.*", "\\1", `First Tooltip`)))]
    setnames(res, "TEMP", var_name)
    return(res)
}

conv <- function (file_name, var_name) {
    dt = read_data(file_name)
    dt = get_latest_period(dt)
    res = dt[, .(Location, TEMP = as.numeric(gsub("^(.*)\\s.*", "\\1", `First Tooltip`)))]
    setnames(res, "TEMP", var_name)
    return(res)
}

sel <- function (file_name, var_name) {
    dt = read_data(file_name)
    dt = get_latest_period(dt)
    res = dt[, .(Location, TEMP = `First Tooltip`)]
    setnames(res, "TEMP", var_name)
    return(res)
}

```

```{r file_definitions, include=F}
# Depending on the structure of the file, it needs to be processed by a different function
# Here I define which files need to be processed by which function

health_data_directory = "C:/Users/George/Desktop/Projects/Happiness/World health data/"

filter_conv_files = c("HEALTHY_LIFE_EXP" = "HALElifeExpectancyAtBirth.csv", 
                "CCDR3070" = "30-70cancerChdEtc.csv",
                "CHILD_MORT" = "under5MortalityRate.csv",
                "ALCOHOL_AB" = "alcoholSubstanceAbuse.csv",
                #"POL_DRATE" = "airPollutionDeathRate.csv",
                "WASH_MORT" = "mortalityRateUnsafeWash.csv",
                "POISON_MORT" = "mortalityRatePoisoning.csv")

conv_files = c("MATERNAL_MORT" = "maternalMortalityRatio.csv", 
                  "TUBERC" = "incedenceOfTuberculosis.csv")

sel_files = c("NTD" = "interventionAgianstNTDs.csv",
              "ROADTRAFFIC_MORT" = "roadTrafficDeaths.csv",
              "UNIV_HEALTHCARE" = "uhcCoverage.csv",
              "MEDICS" = "medicalDoctors.csv",
              "DENTISTS" = "dentists.csv",
              "DRINKING_WATER" = "basicDrinkingWaterServices.csv",
              "CLEAN_FUEL_TECH" = "cleanFuelAndTech.csv")


file_cat_l = list(filter_conv_files, conv_files, sel_files)
function_l = list(filter_conv, conv, sel)

```


```{r loading_world_health, out.width="100%", echo = F}
world_health_dt = concatenate_health_files(file_cat_l, function_l)
setnames(world_health_dt, "Location", "Country")

knitr::kable(head(world_health_dt[, .SD, .SDcols = 1:6]))
```

Took a bit longer but looks good as well! `r emo::ji("check")`

## 1.4 Merging the information by country

All three datasets contain country information. While this is a great start, as you can imagine they do not match exactly in the names and therefore some interventions are required to align them.  
Feel free to go through the code for extra details regarding the matching performed! 

```{r matching_countries, echo=F}

# Manual fixing countries
hap_dt[Country == 'Taiwan Province of China', Country := "Taiwan"]
hap_dt[Country == 'Hong Kong S.A.R. of China', Country := "Hong Kong"]
hap_dt[Country == 'Congo (Brazzaville)', Country := "Republic of the Congo"]
hap_dt[Country == 'Gambia', Country := "The Gambia"]
hap_dt[Country == 'Palestinian Territories', Country := "Palestine"]
hap_dt[Country == 'Swaziland', Country := "Eswatini"]

# Manual fixes
world_health_dt[Country == "Czechia", Country := "Czech Republic"]
world_health_dt[Country == "Democratic People's Republic of Korea", Country := "North Korea"]
world_health_dt[Country == "Republic of Korea", Country := "South Korea"]
world_health_dt[Country == "Viet Nam", Country := "Vietnam"]
world_health_dt[Country == "Côte d’Ivoire", Country := "Ivory Coast"]
world_health_dt[Country == "The former Yugoslav Republic of Macedonia", Country:="North Macedonia"]
world_health_dt[Country == "Gambia", Country := "The Gambia"]
world_health_dt[Country == "Congo", Country := "Republic of the Congo"]


missing_countries = hap_dt[!Country %in% world_health_dt$Country, Country]

# Automatic fixes
for (missing_country in missing_countries) {
    world_health_dt[grepl(missing_country, Country), Country := missing_country]    
}

input_dt = merge(hap_dt, world_dt, by = "Country") %>% merge(world_health_dt, by = "Country")
knitr::kable(head(input_dt[, .SD, .SDcols = 1:11]))
```

Bam! The datasets have been merged and we can start with the analysis `r emo::ji("fireworks")`



# 2. EDA

## 2.1 Missing values

## 2.1.1 Missing values by country


```{r missing_by_country, out.width="100%", echo=F}
top_missing_by_country = head(input_dt[, .(`Missing values`=sum(sapply(.SD, is.na))), by = Country][order(-`Missing values`)], 20)
ggplot(top_missing_by_country, aes(x=reorder(Country, `Missing values`), y = `Missing values`, fill = ifelse(Country== "Palestine", "Prob", "Fine"))) +
  geom_col() + 
  coord_flip() +
  scale_y_continuous(expand = expansion(add = 0.05)) + 
  scale_fill_manual(values = c("Prob" = muted("red"), "Fine" = muted("green")), guide="none") +
  theme(panel.grid = element_blank(),
        plot.title = element_blank(),
            legend.title = element_blank(),
            axis.title.y = element_blank(), 
            panel.border = element_blank(),
            axis.line.x.bottom  = element_line(color = 'gray'),
            axis.line.y.left  = element_line(color = 'gray'))


```

Clearly, there is not enough information for Palestine, therefore I will exclude it from further analysis.

### 2.1.2 Missing values by variable


```{r missing_by_variable, out.width="100%", echo=F}
input_dt = input_dt[Country != "Palestine"]

missing_by_var = input_dt[, sapply(.SD, function(x) sum(is.na(x))/ length(x))]
missing_by_var_dt = data.table(variable = names(missing_by_var), `Missing %` = missing_by_var)[`Missing %` > 0]

ggplot(missing_by_var_dt, aes(x=reorder(variable, `Missing %`), y=`Missing %`)) +
  geom_col(fill= "blue") +
  coord_flip() + 
  scale_y_continuous(expand = expansion(add = 0), labels = percent) + 
  theme(panel.grid = element_blank(),
            legend.title = element_blank(),
            axis.title.y = element_blank(), 
            panel.border = element_blank(),
            axis.line.x.bottom  = element_line(color = 'gray'),
            axis.line.y.left  = element_line(color = 'gray'))



```

Child mortality is the highest with around 12% of the available values missing, but besides that the rest of the variables are very well populated.

## 2.2 Exploring happiness

### 2.2.1 World view

```{r world_hap_prep, include = F}
world = ne_countries(scale = "medium", returnclass = "sf")

hap_world = merge(world, input_dt[, .(`ISO-code`, Happiness)], by.x="adm0_a3", by.y="ISO-code", all.x=T)

input_dt[data.table(world[c("continent", "adm0_a3")]), on = c(`ISO-code` = "adm0_a3"), Continent := i.continent]
input_dt[Country == "Maldives", Continent := "Asia"]
input_dt[Country == "Mauritius", Continent := "Africa"]
input_dt[Continent %in% c("Asia", "Oceania"), Continent := "Asia & Oceania"]

```


```{r world_hap_plot, out.width="100%", echo=F}


min_hap = min(hap_world$Happiness, na.rm = T)
max_hap = max(hap_world$Happiness, na.rm = T)
mid_hap = (min_hap + max_hap)/2
my_breaks = c(min_hap, mid_hap, max_hap)
labels = c("Unhappy", "Average", "Happy")

ggplot(data = hap_world) + 
  geom_sf(aes(fill=Happiness)) +
  scale_fill_gradient2(low="blue", mid="beige", high="green3", 
                       midpoint = mid_hap, 
                       breaks = my_breaks,
                       labels = labels) +
  guides(fill = guide_colorbar(title.position = "top",
                               title.hjust = .5,
                               ticks.colour = "white",
                               frame.colour = "black",
                               barwidth = unit(20, "lines"),
                               barheight = unit(.5, "lines"))) +
  labs(title = 'World happiness index 2021') +
  theme(plot.title = element_markdown(hjust= 0.5),
        panel.grid = element_blank(),
        legend.title = element_text(colour = "white"),
        legend.box.margin = margin(-10,0,0,0),
        legend.margin = margin(-10,0,0,0),
        #plot.title = element_text(colour = "white"),
        legend.position = "bottom")
  
```

We can see that on average North America, Europe and Australia appear to be the happiest. But in order to compare across Continents we need a better chart. Luckily, I got you covered:

### 2.2.2 Happiness by Continent


```{r cont_hap_plot, out.width="100%", echo=F}
input_dt[, Continent := fct_reorder(Continent, Happiness)]

cont_dt = input_dt[, c("Country", "Continent", "Happiness")]
#cont_dt = as.data.table(cont_dt)[, geometry := NULL][!is.na(Happiness)]

cont_dt[, region_hap := mean(Happiness), by = Continent]

dystopia_score = 2.43

world_hap_avg = cont_dt[, mean(Happiness)]

set.seed(1)
hap = ggplot(cont_dt, aes(x = Continent, y = Happiness, color = Continent)) +
      geom_jitter(size = 2, alpha = 0.25, width = 0.2) +
      stat_summary(fun = mean, geom = "point", size = 5) +
      geom_hline(aes(yintercept = world_hap_avg), color = "gray70", size = 0.6) +
      geom_segment(
        aes(x = Continent, xend = Continent,
            y = world_hap_avg, yend = region_hap),
        size = 0.8
      ) +
      coord_flip() +
      scale_y_continuous(limits = c(dystopia_score, 8), expand = c(0.005, 0.005)) +
        scale_color_uchicago() +
        labs(x = NULL, y = "Happiness index") +
        theme(
          legend.position = "none",
          #axis.title = element_text(size = 18),
          axis.text = element_text(family = "Roboto Mono"), #size = 16),
          panel.grid = element_blank()
        )
 
hap_text = hap +
  annotate(
    "text", x = 4.3, y = 4.8, family = "Poppins", size = 6, color = "gray20", lineheight = .7,
    label = glue::glue("Worldwide\n average:{round(world_hap_avg, 1)}")) +
  annotate(
    "text", x = 3, y = 7.3, family = "Poppins", size = 6, color = "gray20", lineheight = .7,
    label = "Continental\n average") +
  annotate(
    "text", x = 4.4, y = 3.1, family = "Poppins", size = 6, color = "gray20", lineheight = .9,
    label = "Haiti") +
  annotate(
    "text", x = 2.6, y = 3, family = "Poppins", size = 6, color = "gray20", lineheight = .9,
    label = "Afghanistan")
  
arrows <-
  tibble(
    x1 = c(4, 3, 3, 4.4, 2.5),
    x2 = c(3.5, 3.8, 3, 3.9, 2),
    y1 = c(4.8, 7, 7, 3.3, 3),
    y2 = c(world_hap_avg, 6.2, 6, 3.6, 2.6)
  )

hap_text +
  geom_curve(
    data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
    arrow = arrow(length = unit(0.07, "inch")), size = 1.2,
    color = "gray20", curvature = -0.3
  )  
  

```

### 2.2.3 Happiness and GDP

```{r happiness_GDP, out.width="100%", echo=F}

hap_gdp_dt = input_dt[, .(Country, `GDP per capita`, Happiness, Continent)]



hap_gdp_plot = ggplot(hap_gdp_dt, aes(x=`GDP per capita`, y = Happiness, label=Country)) +
                      geom_point(aes(color=Continent), alpha = 0.6, size = 2) +
                      stat_smooth(method = "lm", se = T, formula = y ~ x + I(x^2),
                                   color = "grey20", size = 0.8) +
                      scale_x_continuous(labels = comma) +
                      scale_color_uchicago() +
                      labs(x = "GDP per capita ($)") +
                      theme(panel.grid = element_blank(),
                            legend.position = "top",
                            legend.title=element_blank())

ggplotly(hap_gdp_plot) %>% 
  layout(legend = list(orientation = "h", title="", y=4))

```

In the chart you can see the line that I thought best fit the relationship. It turns out that higher GDP does to coincide with higher happiness but the relationship stops being linear above certain values.

### 2.2.4 Happiness and meat consumption


```{r happiness_meat, out.width="100%", echo=F, warning=FALSE}
hap_meat_dt = input_dt[, .(Country, `Meat consumption`, Happiness, Continent)]


hap_meat_plot = ggplot(hap_meat_dt, aes(x=`Meat consumption`, y = Happiness, label=Country )) +
  geom_point(aes(color=Continent), alpha = 0.6, size = 2) +
  stat_smooth(method = "lm", se = T, formula=y~x,
               color = "grey20", size = 0.8) +
  scale_x_continuous(labels = comma) +
  scale_color_uchicago() +
  labs(x = "Meat consumption per capita (kg)") +
  theme(legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank())


ggplotly(hap_meat_plot) %>% 
  layout(legend = list(orientation = "h", title="", y=4))


```

Ok the results are in, eating meat makes people happy, bring in the forks and knives!`r emo::ji("knife")`   
In reality, what we are seeing here might be due to the fact that in order to be able to afford eating meat at a higher volume, most likely the country GDP is relatively high or the food availability is generally higher.  
**These plots simply show correlation and nothing else!!**






Time to clean `r emo::ji("broom")` 

As always, we need to start by addressing potential issues in the dataset. 



We can try to address this using the mice package

Imputing with mice `r emo::ji("broom")` 

Mice offers some nice visuals to better understand missingness in the data. Let's see what patters are present in the dataset.

```{r fig.width=12}
input_dt[, Continent := as.factor(Continent)]
names(input_dt) = make.names(names(input_dt))
t = md.pattern(input_dt[, -c("Country")], rotate.names = T)
```

The missingness pattern chart is very informative about where we have the missing values.  
Each row indicates a pattern (for example the second row corresponds to dataset rows where only the CHILD_MORT variable is missing) and a number on the left with how many such rows exist in the dataset (there are 14 rows in the dataset where only the CHILD_MORT variable is missing)  
The columns indicate missingness by variable, for example there are 4 observations that do not have the Life.expectency variable filled in.
The column on the right counts the total rows in the dataset where we have at least one missing variable (in our case 39)

Let's impute those values. The idea behind `mice` is to produce multiple imputed datasets, apply the analysis that we want to perform on them and then pool the results.

The imputation that I chose is the `cart` one which uses classification and regression trees. For more information, have a look [here](https://stefvanbuuren.name/fimd/sec-cart.html).
To see whether the imputation values look plausible we can plot them together with the original dataset. 

```{r missing value imputation, fig.width=10, fig.height=8}

missing_vars = missing_by_var_dt[`Missing %` > 0, unique(variable)]

imp = mice(input_dt[, -c("Country", "ISO.code")], printFlag = F, method="cart")

formula_txt = paste(paste0( missing_vars, collapse=" + "), " ~ .imp", sep="")

stripplot(imp, Fertility + Life.expectancy + Meat.consumption + Median.age + 
    Urbanization.rate + CHILD_MORT + ROADTRAFFIC_MORT + DENTISTS + 
    CLEAN_FUEL_TECH ~ .imp, pch=20, cex=2, alpha=0.7, main="Imputed values by variable and imputation number")

```

Imputation number 1 is the original dataset and therefore does not contain any red points. All the imputed values look plausible given the range of the dataset.

MICE has produced multiple (5) full datasets. We could perform the analysis on each one of them and then pool the results, but for this notebook I simply averaged the results.  
`emo::ji("warning")` Depending on the analysis this [might not be correct](https://stefvanbuuren.name/fimd/workflow.html#sec:badworkflowa).


```{r}

mice_output <- complete(imp)

new_dt = data.table(mice_output)
new_dt[, Country := input_dt$Country]


imp =  mice(input_dt[, -c("Country", "ISO.code")], method="rf")
mice.mids(imp, maxit=35, print=F)
stripplot(imp, CHILD_MORT + Life.expectancy~.imp, pch=20, cex=2)
```


```{r fig.height=12, fig.width=10}
library(corrplot)
descrCor = cor(input_dt[, -c("Country", "ISO.code", "Continent", "Happiness")], use="complete.obs")
corrplot(descrCor, order = 'AOE', type = 'upper', tl.col="black")

```

```{r}
library(caret)

highlyCorDescr <- findCorrelation(descrCor, cutoff = .7, names=T)



remove_cols = c(highlyCorDescr, "Country", "ISO.code", "Continent")
filt_inp_dt = input_dt[, -..remove_cols]

newCor = cor(filt_inp_dt[, -c("Continent", "Happiness")], use="complete.obs")
corrplot(newCor, order = 'AOE', type = 'upper', tl.col="black")

filt_inp_dt[is.na(Urbanization.rate), Urbanization.rate := 100]
filt_inp_dt[is.na(DENTISTS), DENTISTS:=0.4]

```

```{r}

preProcValues <- preProcess(filt_inp_dt[, -c("Happiness")], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, filt_inp_dt[, -c("Happiness")])

mod_inp_dt = cbind(trainTransformed, Happiness = filt_inp_dt$Happiness)

xa = lm(Happiness ~ ., data = mod_inp_dt)

par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(xa)

```




